{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"트랜스퍼 파이널.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"511643d49c5c4297bbef7070d58a76ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_54280770d41546b997909306ce2079d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0a7335bbbc84a2c90b9a97388e76062","IPY_MODEL_5cf9828ed77548198cf361abcd2046c2"]}},"54280770d41546b997909306ce2079d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0a7335bbbc84a2c90b9a97388e76062":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f147d423a45b49a29ae786477f815470","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":46827520,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46827520,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6d76537419e347a09c1e710cd2e83db5"}},"5cf9828ed77548198cf361abcd2046c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7df5ea7b278f462f9d36cb0f7ef700b1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 44.7M/44.7M [00:03&lt;00:00, 14.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb64976fc9c1455a87b0288692b715c1"}},"f147d423a45b49a29ae786477f815470":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6d76537419e347a09c1e710cd2e83db5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7df5ea7b278f462f9d36cb0f7ef700b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bb64976fc9c1455a87b0288692b715c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"F1bPPSg1NZJm"},"source":["# 재구축 데이터셋 Transfer\n"]},{"cell_type":"code","metadata":{"id":"dHIByFLlYcpy"},"source":["import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, models\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset\n","from PIL import Image\n","import numpy as np\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfU_Y_gSMc42","colab":{"base_uri":"https://localhost:8080/"},"outputId":"64c646b2-595e-44e1-821f-0459bf3daf72"},"source":["# 구축된 .npy파일을 Pytorch DataLoader을 사용할 수 있도록 CUSTOM DATASET을 만듬.\n","import numpy as np\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","class CUB200(data.Dataset):\n","    def __init__(self, Train, transform = None):\n","        super(CUB200, self).__init__()\n","        \"\"\"\n","        Train : bool = True\n","        \"\"\"\n","        if Train == True:\n","            load_data = np.load('/content/drive/My Drive/colab_data/cub/final/train_data.npy')\n","            load_label = np.load('/content/drive/My Drive/colab_data/cub/final/train_label.npy')\n","            self.image = load_data\n","            self.label = load_label\n","            self.transform = transform\n","            \n","        else:\n","            load_data = np.load('/content/drive/My Drive/colab_data/cub/final/test_data.npy')\n","            load_label = np.load('/content/drive/My Drive/colab_data/cub/final/test_label.npy')\n","            self.image = load_data\n","            self.label = load_label\n","            self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img, target = self.image[index], self.label[index]\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.image)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"245P8QOlMjkD","outputId":"a96d4c31-a652-4d47-ed15-eb0630487e46"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5TkTeovfMkvI"},"source":["# train_data에만 data augmentaion을 적용함.\n","transform_train = transforms.Compose([\n","        transforms.RandomCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n","\n","transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ytid3c0vMlsI"},"source":["# CUSTOM DATASET을 이용하여 train_loader, test_loader을 구축.\n","\n","batch_size = 8\n","\n","train_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(True, transform = transform_train),\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(False, transform = transform_test),\n","    batch_size = batch_size,\n","    shuffle = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Vlnqo9sM1DH"},"source":["def training_model(model, criterion, optimizer, scheduler, num_epochs = 25):\n","\n","\n","    for epoch in range(num_epochs):\n","        scheduler.step()\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            if i % 20 == 19:\n","                print('[%d, %5d] loss: %.7f' %\n","                    (epoch + 1, (i + 1), running_loss / 20))\n","                running_loss = 0.0\n","        \n","        train_correct = 0\n","        train_total = 0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs = inputs.squeeze()\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_total += labels.size(0)\n","            train_correct += (predicted == labels).sum().item()\n","\n","        print('[%d epoch] Accuracy of the network on the train images: %d %%' %\n","              (epoch + 1, 100 * train_correct / train_total))\n","        \n","    print(\"End Training do it eval_accuracy\")\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmDHs5-65Ycs"},"source":["def eval_accuracy(model):\n","    class_correct = list(0. for i in range(50))\n","    class_total = list(0. for i in range(50))\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for i, data in enumerate(test_loader, 0):\n","            images, labels = data\n","            images = images.squeeze()\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            c = (predicted == labels).squeeze()\n","                    \n","            for i in range(labels.shape[0]):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","                \n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on test images: %d %%' % (\n","        100 * correct / total))            \n","                \n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmLU_Fo4Wedv","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["511643d49c5c4297bbef7070d58a76ab","54280770d41546b997909306ce2079d2","e0a7335bbbc84a2c90b9a97388e76062","5cf9828ed77548198cf361abcd2046c2","f147d423a45b49a29ae786477f815470","6d76537419e347a09c1e710cd2e83db5","7df5ea7b278f462f9d36cb0f7ef700b1","bb64976fc9c1455a87b0288692b715c1"]},"outputId":"523315f2-fcc7-4e0a-a17b-9fc2bf9057eb"},"source":["\n","model_ft = models.resnet18(pretrained=True)\n","for param in model_ft.parameters():\n","    param.requires_grad = False\n","num_ftrs = model_ft.fc.in_features\n","\n","print(model_ft)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"511643d49c5c4297bbef7070d58a76ab","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGLm0LiXbNC-","outputId":"2a2e5a6c-4157-4d58-e8cd-1a6475c0a34f"},"source":["model_ft.fc = nn.Linear(num_ftrs, 50)\n","print(model_ft)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=50, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u5cIKBkGNF1a"},"source":["num_epochs = 14\n","model_ft.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model_ft.parameters(), lr = 0.001, momentum = 0.9)\n","lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjcQV0A6M3bx","outputId":"4d87416b-ccf9-4bf5-e8ea-8f6e898fe213"},"source":["model_ft = training_model(model_ft, criterion, optimizer, lr_scheduler, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[1,    20] loss: 4.1536471\n","[1,    40] loss: 4.0113531\n","[1,    60] loss: 3.9311775\n","[1,    80] loss: 3.7014040\n","[1,   100] loss: 3.5988341\n","[1 epoch] Accuracy of the network on the train images: 21 %\n","[2,    20] loss: 3.2102790\n","[2,    40] loss: 3.2316812\n","[2,    60] loss: 2.9793361\n","[2,    80] loss: 3.0863408\n","[2,   100] loss: 2.9682474\n","[2 epoch] Accuracy of the network on the train images: 44 %\n","[3,    20] loss: 2.5998820\n","[3,    40] loss: 2.5673404\n","[3,    60] loss: 2.5602632\n","[3,    80] loss: 2.5374383\n","[3,   100] loss: 2.4081615\n","[3 epoch] Accuracy of the network on the train images: 57 %\n","[4,    20] loss: 2.1768454\n","[4,    40] loss: 2.1378457\n","[4,    60] loss: 2.0087677\n","[4,    80] loss: 2.0699135\n","[4,   100] loss: 2.0526524\n","[4 epoch] Accuracy of the network on the train images: 68 %\n","[5,    20] loss: 1.8223425\n","[5,    40] loss: 1.9086864\n","[5,    60] loss: 1.7018415\n","[5,    80] loss: 1.7030180\n","[5,   100] loss: 1.7270878\n","[5 epoch] Accuracy of the network on the train images: 72 %\n","[6,    20] loss: 1.6107359\n","[6,    40] loss: 1.4669489\n","[6,    60] loss: 1.6072153\n","[6,    80] loss: 1.5419894\n","[6,   100] loss: 1.6407359\n","[6 epoch] Accuracy of the network on the train images: 74 %\n","[7,    20] loss: 1.3176140\n","[7,    40] loss: 1.4161318\n","[7,    60] loss: 1.3790242\n","[7,    80] loss: 1.4544303\n","[7,   100] loss: 1.3890633\n","[7 epoch] Accuracy of the network on the train images: 79 %\n","[8,    20] loss: 1.2687752\n","[8,    40] loss: 1.3662797\n","[8,    60] loss: 1.4114615\n","[8,    80] loss: 1.4435156\n","[8,   100] loss: 1.3674289\n","[8 epoch] Accuracy of the network on the train images: 81 %\n","[9,    20] loss: 1.3313551\n","[9,    40] loss: 1.3785010\n","[9,    60] loss: 1.2774306\n","[9,    80] loss: 1.2793029\n","[9,   100] loss: 1.2776426\n","[9 epoch] Accuracy of the network on the train images: 82 %\n","[10,    20] loss: 1.2474431\n","[10,    40] loss: 1.3267963\n","[10,    60] loss: 1.4095558\n","[10,    80] loss: 1.2325052\n","[10,   100] loss: 1.1645059\n","[10 epoch] Accuracy of the network on the train images: 80 %\n","[11,    20] loss: 1.2454733\n","[11,    40] loss: 1.3379963\n","[11,    60] loss: 1.3666289\n","[11,    80] loss: 1.2978947\n","[11,   100] loss: 1.3024192\n","[11 epoch] Accuracy of the network on the train images: 80 %\n","[12,    20] loss: 1.2053428\n","[12,    40] loss: 1.3016124\n","[12,    60] loss: 1.2741149\n","[12,    80] loss: 1.3395448\n","[12,   100] loss: 1.2471977\n","[12 epoch] Accuracy of the network on the train images: 81 %\n","[13,    20] loss: 1.1884739\n","[13,    40] loss: 1.2575810\n","[13,    60] loss: 1.2933732\n","[13,    80] loss: 1.2709620\n","[13,   100] loss: 1.2749202\n","[13 epoch] Accuracy of the network on the train images: 81 %\n","[14,    20] loss: 1.2025629\n","[14,    40] loss: 1.2756108\n","[14,    60] loss: 1.1728457\n","[14,    80] loss: 1.3392537\n","[14,   100] loss: 1.2556493\n","[14 epoch] Accuracy of the network on the train images: 82 %\n","End Training do it eval_accuracy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xaCtc86RPepo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2dafbf5a-af5d-48ab-ea2b-fe095a4ce237"},"source":["eval_accuracy(model_ft)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 500 test images: 57 %\n"],"name":"stdout"}]}]}