{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"aihcw_ogs_extend.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"GPL8Me3fl8oO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHIByFLlYcpy","executionInfo":{"status":"ok","timestamp":1623396085304,"user_tz":-540,"elapsed":2597,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, models\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset\n","from PIL import Image\n","import numpy as np\n","from tqdm import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfU_Y_gSMc42","executionInfo":{"status":"ok","timestamp":1623396135542,"user_tz":-540,"elapsed":26593,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}},"outputId":"283c96bc-4b93-4271-e1b8-c539ac3c657d"},"source":["# 구축된 .npy파일을 Pytorch DataLoader을 사용할 수 있도록 CUSTOM DATASET을 만듬.\n","import numpy as np\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","from skimage.transform import resize\n","\n","drive.mount('/content/drive')\n","default_path = \"/content/drive/My Drive/인공지능 수업/final/\"\n","\n","CUB200_TYPE_TRAIN = 1\n","CUB200_TYPE_TEST = 2\n","CUB200_TYPE_SUBMIT = 3\n","\n","original_train_data = np.load(default_path + 'train_image.npy')\n","original_train_label = np.load(default_path + 'train_label.npy')\n","\n","# Additional\n","# additional_train_data = np.load(default_path + 'additional_image.npy')\n","# additional_train_label = np.load(default_path + 'additional_label.npy')\n","# original_train_data = np.concatenate((original_train_data, additional_train_data), axis=0)\n","# original_train_label = np.concatenate((original_train_label, additional_train_label), axis=0)\n","\n","# Extend\n","extend_train_image = np.load(default_path + 'extend_image.npy', allow_pickle=True)\n","extend_train_label = np.load(default_path + 'extend_label.npy', allow_pickle=True)\n","print(extend_train_image.shape)\n","print(original_train_data.shape)\n","original_train_data = np.concatenate((original_train_data, extend_train_image), axis=0)\n","original_train_label = np.concatenate((original_train_label, extend_train_label), axis=0)\n","\n","\n","train_data, test_data, train_label, test_label = train_test_split(\n","    original_train_data,\n","    original_train_label,\n","    test_size = 0.1,\n","    random_state = 1)\n","\n","# train_data = original_train_data\n","# train_label = original_train_label\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","(2958, 256, 256, 3)\n","(895, 256, 256, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"npyGmpDf2yD6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbqxC8fyuoy2","executionInfo":{"status":"ok","timestamp":1623396143079,"user_tz":-540,"elapsed":269,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["class CUB200(data.Dataset):\n","\n","    def __init__(self, type, transform = None):\n","        super(CUB200, self).__init__()\n","        \"\"\"\n","        type : int = 1, 2, 3\n","        \"\"\"\n","        \n","        if type == CUB200_TYPE_TRAIN:\n","          self.image = train_data\n","          self.label = train_label\n","        elif type == CUB200_TYPE_TEST:\n","          self.image = test_data\n","          self.label = test_label\n","        elif type == CUB200_TYPE_SUBMIT:\n","          self.image = np.load(default_path + 'test_image.npy')\n","          self.label = np.zeros(500)\n","        \n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img, target = self.image[index], self.label[index]\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.image)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QH5Xj02Vgu5","executionInfo":{"status":"ok","timestamp":1623396147898,"user_tz":-540,"elapsed":1978,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}},"outputId":"4b30736d-0ec8-40a2-f658-315550dbe98d"},"source":["trainCUB = CUB200(CUB200_TYPE_TRAIN)\n","print(trainCUB.image.shape)\n","print(trainCUB.label.shape)\n","\n","testCUB = CUB200(CUB200_TYPE_TEST)\n","print(testCUB.image.shape)\n","print(testCUB.label.shape)\n","# print(np.max(testCUB.label), np.min(testCUB.label))\n","\n","submitCUB = CUB200(CUB200_TYPE_SUBMIT)\n","print(submitCUB.image.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(3467, 256, 256, 3)\n","(3467,)\n","(386, 256, 256, 3)\n","(386,)\n","(500, 256, 256, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"245P8QOlMjkD","executionInfo":{"status":"ok","timestamp":1623396147899,"user_tz":-540,"elapsed":4,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}},"outputId":"686aa493-3316-4452-e02c-64a3640c81f5"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5TkTeovfMkvI","executionInfo":{"status":"ok","timestamp":1623396428346,"user_tz":-540,"elapsed":307,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["transform_train = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.RandomCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n","\n","transform_test = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ytid3c0vMlsI","executionInfo":{"status":"ok","timestamp":1623396152335,"user_tz":-540,"elapsed":274,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["# CUSTOM DATASET을 이용하여 train_loader, test_loader을 구축\n","\n","batch_size = 32\n","\n","train_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(CUB200_TYPE_TRAIN, transform = transform_train),\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(CUB200_TYPE_TEST, transform = transform_test),\n","    batch_size = batch_size,\n","    shuffle = False\n",")\n","\n","submit_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(CUB200_TYPE_SUBMIT, transform = transform_test),\n","    batch_size = batch_size,\n","    shuffle = False\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Vlnqo9sM1DH","executionInfo":{"status":"ok","timestamp":1623396162195,"user_tz":-540,"elapsed":271,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["def training_model(model, criterion, optimizer, scheduler, num_epochs = 25):\n","\n","    for epoch in range(num_epochs):\n","        #scheduler.step()\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            if i % 60 == 59:\n","                print('[%d, %5d] loss: %.7f' %\n","                    (epoch + 1, (i + 1), running_loss / 20))\n","                running_loss = 0.0\n","        \n","        # gunmo\n","        scheduler.step()\n","\n","\n","        train_correct = 0\n","        train_total = 0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs = inputs.squeeze()\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_total += labels.size(0)\n","            train_correct += (predicted == labels).sum().item()\n","\n","        print('[%d epoch] Accuracy of the network on the train images: %d %%' %\n","              (epoch + 1, 100 * train_correct / train_total))\n","        \n","    print(\"End Training do it eval_accuracy\")\n","    return model"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmDHs5-65Ycs","executionInfo":{"status":"ok","timestamp":1623396165716,"user_tz":-540,"elapsed":281,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["def eval_accuracy(model):\n","    class_correct = list(0. for i in range(50))\n","    class_total = list(0. for i in range(50))\n","\n","    correct = 0\n","    total = 0\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(test_loader, 0):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            c = (predicted == labels).squeeze()\n","                    \n","            for i in range(labels.shape[0]):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","                \n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on test images: %d %%' % (\n","        100 * correct / total))            \n","                \n","    return 100 * correct / total"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9rGPkc-8TiX","executionInfo":{"status":"ok","timestamp":1623396169021,"user_tz":-540,"elapsed":271,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}}},"source":["def eval_accuracy2(model1,model2,model3, model4):\n","    class_correct = list(0. for i in range(50))\n","    class_total = list(0. for i in range(50))\n","\n","    correct = 0\n","    total = 0\n","    \n","    model1.eval()\n","    model2.eval()\n","    model3.eval()\n","    model4.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(test_loader, 0):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs1 = model1(images)\n","            outputs2 = model2(images)\n","            outputs3 = model3(images)\n","            outputs4 = model4(images)\n","            outputs = (outputs1+outputs2+outputs3+outputs4)/4\n","            _, predicted = torch.max(outputs, 1)\n","            c = (predicted == labels).squeeze()\n","                    \n","            for i in range(labels.shape[0]):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","                \n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on test images: %d %%' % (\n","        100 * correct / total))            \n","                \n","    return "],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoAfC_44xBek"},"source":["class Interpolate(nn.Module):\n","    def __init__(self, size, mode):\n","        super(Interpolate, self).__init__()\n","        self.interp = nn.functional.interpolate\n","        self.size = size\n","        self.mode = mode\n","        \n","    def forward(self, x):\n","        x = self.interp(x, size=self.size, mode=self.mode, align_corners=True)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3EEoaTMP8XJb","executionInfo":{"status":"ok","timestamp":1623396435339,"user_tz":-540,"elapsed":268,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}},"outputId":"cd585e3f-220f-4e79-8ba8-ae41f220c643"},"source":["linear1 = nn.Linear(2048, 50, bias=True)\n","linear1_1 = nn.Linear(2048, 1024, bias=True)\n","linear1_2 = nn.Linear(2048, 50, bias=True)\n","linear1_3 = nn.Linear(2048, 50, bias=True)\n","linear2 = nn.Linear(1024, 512, bias=True)\n","linear3 = nn.Linear(512, 50, bias=True)\n","dropout = nn.Dropout(0.25)\n","relu = nn.ReLU()\n","\n","# xavier initialization\n","nn.init.xavier_uniform_(linear1.weight)\n","nn.init.xavier_uniform_(linear1_1.weight)\n","nn.init.xavier_uniform_(linear1_2.weight)\n","nn.init.xavier_uniform_(linear1_3.weight)\n","nn.init.xavier_uniform_(linear2.weight)\n","#nn.init.xavier_uniform_(linear3.weight)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 0.0625, -0.0584,  0.0064,  ...,  0.0084, -0.0294, -0.0009],\n","        [-0.0419,  0.0343,  0.0370,  ...,  0.0604,  0.0173,  0.0264],\n","        [-0.0400,  0.0218, -0.0583,  ..., -0.0558, -0.0077, -0.0385],\n","        ...,\n","        [ 0.0256,  0.0181,  0.0599,  ...,  0.0426,  0.0604, -0.0218],\n","        [ 0.0191,  0.0469, -0.0469,  ...,  0.0105, -0.0156,  0.0511],\n","        [ 0.0566,  0.0193,  0.0384,  ...,  0.0499,  0.0578, -0.0499]],\n","       requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"51GN41VPZ5vg","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"error","timestamp":1623396694159,"user_tz":-540,"elapsed":257001,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"}},"outputId":"efa9c0f8-df23-4181-dc4d-697e6731eddc"},"source":["#resnext101\n","#스케줄러: 스텝 LR\n","#옵티마이저: SGD, weight_decay=0\n","model_rsn = models.resnext101_32x8d(pretrained=True)\n","\n","for param in model_rsn.parameters():\n","  param.requires_grad = False\n","#print(model_rsn)\n","model_rsn.fc = nn.Sequential(\n","        linear1\n","    )\n","#print(model_rsn)\n","\n","num_epochs = 25\n","model_rsn.to(device)\n","criterion = nn.CrossEntropyLoss()\n","\n","#optimizer = optim.Adam(model_rsn.parameters(), lr = 0.001)\n","optimizer = optim.Adam(model_rsn.parameters(), lr=0.0008, weight_decay=0)\n","lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.99)\n","\n","model_rsn = training_model(model_rsn, criterion, optimizer, lr_scheduler, num_epochs)\n","\n","# eval_accuracy(model_rsn)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[1,    60] loss: 11.0340208\n","[1 epoch] Accuracy of the network on the train images: 43 %\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-b5563f4dcd87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel_rsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# eval_accuracy(model_rsn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-8cab7a1aaba0>\u001b[0m in \u001b[0;36mtraining_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"YSLXg--VzhAi"},"source":["# memory footprint support libraries/code\n","# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","# !pip install gputil\n","# !pip install psutil\n","# !pip install humanize\n","\n","# import psutil\n","# import humanize\n","# import os\n","# import GPUtil as GPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIUPBgFCxzUG"},"source":["# GPUs = GPU.getGPUs()\n","# # XXX: only one GPU on Colab and isn’t guaranteed\n","# gpu = GPUs[0]\n","# def printm():\n","#     process = psutil.Process(os.getpid())\n","#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","# printm()\n","\n","import torch, gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjcQV0A6M3bx","outputId":"ccccf6ca-fa7d-4fc8-e2b5-34fd03f327e2"},"source":["num_epochs = 16\n","model_ft.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_ft.parameters(), lr = 0.0008)\n","# optimizer = optim.SGD(model_ft.parameters(), lr=0.0075, momentum=0.9)\n","lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 16, gamma = 0.1)\n","# lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20,40], gamma= 0.1)  \n","\n","model_ft = training_model(model_ft, criterion, optimizer, lr_scheduler, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[1,    60] loss: 9.1423422\n","[1 epoch] Accuracy of the network on the train images: 75 %\n","[2,    60] loss: 3.6406914\n","[2 epoch] Accuracy of the network on the train images: 82 %\n","[3,    60] loss: 2.4515760\n","[3 epoch] Accuracy of the network on the train images: 86 %\n","[4,    60] loss: 1.8878198\n","[4 epoch] Accuracy of the network on the train images: 87 %\n","[5,    60] loss: 1.6446251\n","[5 epoch] Accuracy of the network on the train images: 87 %\n","[6,    60] loss: 1.4065498\n","[6 epoch] Accuracy of the network on the train images: 90 %\n","[7,    60] loss: 1.3054651\n","[7 epoch] Accuracy of the network on the train images: 90 %\n","[8,    60] loss: 1.0814185\n","[8 epoch] Accuracy of the network on the train images: 89 %\n","[9,    60] loss: 1.1059019\n","[9 epoch] Accuracy of the network on the train images: 90 %\n","[10,    60] loss: 0.9657002\n","[10 epoch] Accuracy of the network on the train images: 93 %\n","[11,    60] loss: 0.9279315\n","[11 epoch] Accuracy of the network on the train images: 92 %\n","[12,    60] loss: 0.7896270\n","[12 epoch] Accuracy of the network on the train images: 93 %\n","[13,    60] loss: 0.7865468\n","[13 epoch] Accuracy of the network on the train images: 93 %\n","[14,    60] loss: 0.7846983\n","[14 epoch] Accuracy of the network on the train images: 93 %\n","[15,    60] loss: 0.7698492\n","[15 epoch] Accuracy of the network on the train images: 94 %\n","[16,    60] loss: 0.6091621\n","[16 epoch] Accuracy of the network on the train images: 95 %\n","End Training do it eval_accuracy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xaCtc86RPepo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8658a8d4-ed65-48a4-fb3d-d435e3db638e"},"source":["eval_acc = eval_accuracy(model_ft)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the network on test images: 81 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7aJbryDvNmhQ"},"source":["import itertools\n","\n","def get_result(model):\n","  result = []\n","  confidence = []\n","\n","  model.eval()\n","  with torch.no_grad():\n","    for i, data in enumerate(submit_loader, 0):\n","      images, _ = data\n","      images = images.to(device)\n","      outputs = model(images)\n","      _, predicted = torch.max(outputs, 1)\n","      result.append(predicted.cpu().numpy())\n","\n","      for output in outputs:\n","        confidence.append(torch.max(F.softmax(output, dim=0)).cpu().numpy())\n","  \n","  result = list(itertools.chain(*result))\n","\n","  ca = np.array(confidence)\n","  # print(ca)\n","  confidence_count = len(np.where(ca > 0.9)[0])\n","  print(confidence_count)\n","  \n","  additional_train_data = []\n","  additional_train_label = []\n","\n","  submit_image = submit_loader.dataset.image\n","\n","  # print(result)\n","\n","  for i in np.where(ca > 0.9)[0]:\n","    additional_train_data.append(submit_image[i])\n","    additional_train_label.append(result[i])\n","  \n","  # Remeber prev data\n","  import shutil\n","  shutil.copy(default_path + f\"additional_image.npy\", default_path + f\"additional_library/additional_image_{confidence_count}_{eval_acc}%.npy\")\n","  shutil.copy(default_path + f\"additional_label.npy\", default_path + f\"additional_library/additional_label_{confidence_count}_{eval_acc}%.npy\")\n","  \n","  #store new data\n","  np.save(default_path + \"additional_image.npy\", additional_train_data)\n","  np.save(default_path + \"additional_label.npy\", additional_train_label)\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-rzBUi6FK9s","colab":{"base_uri":"https://localhost:8080/"},"outputId":"53b6db15-77a1-4a6a-c16e-781a581192ab"},"source":["submit_result = get_result(model_ft)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["222\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FUiVgOC2J2R4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"948d3c16-ed91-4c4b-c69f-3a8b050f4ea4"},"source":["print(submit_result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16, 12, 23, 23, 47, 26, 38, 24, 16, 30, 28, 47, 41, 20, 35, 26, 15, 8, 37, 7, 4, 22, 22, 32, 38, 2, 40, 36, 30, 34, 42, 37, 45, 35, 10, 33, 5, 7, 40, 48, 32, 37, 32, 7, 8, 43, 22, 24, 39, 16, 12, 25, 5, 6, 32, 48, 42, 39, 8, 45, 0, 5, 45, 12, 14, 26, 40, 49, 3, 9, 48, 11, 9, 35, 12, 20, 40, 36, 42, 35, 45, 41, 36, 26, 22, 6, 4, 48, 8, 48, 33, 44, 19, 14, 34, 9, 14, 21, 4, 27, 19, 35, 21, 23, 45, 4, 9, 44, 18, 24, 10, 47, 1, 48, 25, 11, 42, 31, 42, 35, 3, 0, 21, 29, 14, 10, 38, 18, 26, 1, 32, 35, 44, 1, 9, 33, 43, 37, 16, 2, 40, 38, 3, 38, 15, 34, 26, 12, 34, 41, 11, 6, 39, 43, 38, 0, 22, 42, 3, 38, 1, 13, 41, 15, 21, 41, 14, 10, 13, 28, 49, 44, 41, 19, 7, 27, 46, 26, 11, 13, 46, 20, 35, 42, 24, 25, 15, 42, 6, 42, 36, 27, 6, 12, 48, 25, 29, 5, 6, 26, 2, 13, 15, 29, 2, 17, 9, 14, 6, 4, 44, 38, 21, 26, 24, 21, 29, 46, 2, 27, 48, 22, 31, 12, 31, 2, 17, 18, 13, 24, 35, 8, 27, 37, 4, 18, 29, 20, 20, 8, 49, 24, 40, 13, 19, 38, 49, 6, 6, 4, 31, 34, 20, 48, 1, 42, 10, 35, 26, 10, 29, 9, 27, 47, 0, 32, 40, 41, 27, 11, 2, 31, 33, 23, 45, 45, 17, 0, 17, 8, 0, 22, 13, 6, 48, 35, 9, 49, 30, 8, 13, 17, 1, 0, 8, 25, 42, 10, 43, 30, 23, 21, 17, 38, 3, 27, 36, 20, 2, 46, 45, 12, 46, 1, 36, 20, 21, 42, 19, 17, 17, 43, 40, 37, 45, 28, 5, 19, 5, 36, 31, 12, 16, 38, 4, 9, 17, 14, 2, 29, 15, 23, 41, 26, 16, 27, 1, 5, 10, 32, 10, 42, 45, 16, 16, 15, 24, 5, 25, 38, 36, 27, 40, 19, 29, 11, 2, 32, 7, 10, 3, 20, 33, 18, 47, 16, 31, 19, 47, 47, 1, 13, 21, 14, 36, 25, 3, 10, 7, 39, 45, 37, 20, 17, 8, 34, 25, 10, 37, 0, 41, 46, 34, 39, 28, 27, 19, 45, 34, 0, 37, 28, 34, 9, 9, 4, 28, 8, 0, 2, 48, 5, 23, 28, 33, 46, 45, 13, 43, 16, 49, 23, 17, 11, 37, 47, 29, 27, 26, 34, 35, 3, 24, 14, 49, 28, 40, 34, 29, 11, 0, 13, 7, 18, 23, 15, 25, 47, 39, 9, 28, 40, 44, 29, 4, 1, 4, 42, 18, 5, 13, 19, 12, 17, 40, 10, 21, 23, 15, 46, 14, 16, 9, 39, 7, 24, 47, 41, 7, 27, 25, 17, 24, 28, 20, 7, 39, 46, 13, 5]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G6ONJVhtKIIh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8de64265-8d27-4feb-dc49-73cf1dd3369c"},"source":["pip install pycryptodomex --no-binary :all:"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pycryptodomex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/e2/a0f9f5452a59bafaa3420585f22b58a8566c4717a88c139af2276bb5695d/pycryptodomex-3.10.1.tar.gz (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 13.7MB/s \n","\u001b[?25hSkipping wheel build for pycryptodomex, due to binaries being disabled for it.\n","Installing collected packages: pycryptodomex\n","    Running setup.py install for pycryptodomex ... \u001b[?25l\u001b[?25hdone\n","Successfully installed pycryptodomex-3.10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8oMQLPBuI7Jo"},"source":["import json\n","from base64 import b64encode\n","from Cryptodome.Cipher import AES\n","from Cryptodome.Util.Padding import pad\n","\n","def read_txt(fileName):\n","    with open(fileName, 'rt') as f:\n","        list_data = [a.strip('\\n\\r') for a in f.readlines()]\n","    return list_data\n","\n","def write_json(fileName, data):\n","    with open(fileName, 'w', encoding='utf-8') as f:\n","        json.dump(data, f, ensure_ascii=False, indent=4)\n","\n","def load_key(key_path):\n","    with open(key_path, \"rb\") as f:\n","        key = f.read()\n","    return key\n","\n","def encrypt_data(key_path, ans_list, encrypt_store_path='ans.json'):\n","    key = load_key(key_path)\n","    print(key)\n","    data = \" \".join([str(i) for i in ans_list])\n","    encode_data = data.encode()\n","    cipher = AES.new(key, AES.MODE_CBC)\n","    ct_bytes = cipher.encrypt(pad(encode_data, AES.block_size))\n","    iv = b64encode(cipher.iv).decode('utf-8')\n","    ct = b64encode(ct_bytes).decode('utf-8')\n","    write_json(encrypt_store_path, {'iv':iv, 'ciphertext':ct})\n","\n","if __name__==\"__main__\":\n","    # 1.이메일을 통해서 전달 받은 키 파일의 경로 입력\n","    key_path = default_path + \"team9.pem\"\n","    # key_path = \"/content/drive/My Drive/ColabNotebooks/aiproject/team9.pem\"\n","    # 2. 예측한 결과를 텍스트 파일로 저장했을 경우 리스트로 다시 불러오기\n","    # 본인이 원하는 방식으로 리스트 형태로 예측 값을 불러오기만 하면 됨(순서를 지킬것)\n","    #raw_ans_path = \"ans.txt\"\n","    #ans = read_txt(raw_ans_path)\n","    #ans에 result 저장한 리스트 넣기\n","    ans = submit_result\n","    # 3. 암호화된 파일을 저장할 위치\n","    encrypt_ans_path = default_path + \"ai_answer.json\"\n","    # 4. 암호화!(pycrytodome 설치)\n","    encrypt_data(key_path, ans, encrypt_ans_path)\n","    print(\"finished!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2E3dovK9Lbv8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21AhnqMiJdQ0"},"source":["0 0 0 0 ... 50\n","...\n","500\n","\n","np.torch([0 0 0 0 0])\n","\n"]}]}