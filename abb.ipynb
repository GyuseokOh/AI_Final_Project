{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aihcw_ogs_extend.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "124607c81649405286b9aeb51492afb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37bb0a0fa6054a438f0f0a16fceb464e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f170bf32404441748b4a4dd03c5f825d",
              "IPY_MODEL_fa55a0847e9a43d784baaec279c41eac"
            ]
          }
        },
        "37bb0a0fa6054a438f0f0a16fceb464e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f170bf32404441748b4a4dd03c5f825d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed42bd36332541a3994d74fe15161b2b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25d7945a5cfe47c3a851a5f2b7b546ed"
          }
        },
        "fa55a0847e9a43d784baaec279c41eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a72ba5e854942398f9112d42f4ed2a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [00:03&lt;00:00, 69.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f189b259501c4aee8f65bfe2de27aa0f"
          }
        },
        "ed42bd36332541a3994d74fe15161b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25d7945a5cfe47c3a851a5f2b7b546ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a72ba5e854942398f9112d42f4ed2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f189b259501c4aee8f65bfe2de27aa0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPL8Me3fl8oO"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHIByFLlYcpy"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfU_Y_gSMc42",
        "outputId": "df3510e0-8d55-4713-b1dc-0d308bf82396"
      },
      "source": [
        "# 구축된 .npy파일을 Pytorch DataLoader을 사용할 수 있도록 CUSTOM DATASET을 만듬.\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "default_path = \"/content/drive/My Drive/Colab Notebooks/final/\"\n",
        "\n",
        "CUB200_TYPE_TRAIN = 1\n",
        "CUB200_TYPE_TEST = 2\n",
        "CUB200_TYPE_SUBMIT = 3\n",
        "\n",
        "original_train_data = np.load(default_path + 'train_image.npy')\n",
        "original_train_label = np.load(default_path + 'train_label.npy')\n",
        "\n",
        "# Additional\n",
        "# additional_train_data = np.load(default_path + 'additional_image.npy')\n",
        "# additional_train_label = np.load(default_path + 'additional_label.npy')\n",
        "# original_train_data = np.concatenate((original_train_data, additional_train_data), axis=0)\n",
        "# original_train_label = np.concatenate((original_train_label, additional_train_label), axis=0)\n",
        "\n",
        "# Extend\n",
        "extend_train_image = np.load(default_path + 'extend_image.npy', allow_pickle=True)\n",
        "extend_train_label = np.load(default_path + 'extend_label.npy', allow_pickle=True)\n",
        "print(extend_train_image.shape)\n",
        "print(original_train_data.shape)\n",
        "original_train_data = np.concatenate((original_train_data, extend_train_image), axis=0)\n",
        "original_train_label = np.concatenate((original_train_label, extend_train_label), axis=0)\n",
        "\n",
        "\n",
        "train_data, test_data, train_label, test_label = train_test_split(\n",
        "    original_train_data,\n",
        "    original_train_label,\n",
        "    test_size = 0.1,\n",
        "    random_state = 1)\n",
        "\n",
        "# train_data = original_train_data\n",
        "# train_label = original_train_label\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(2958, 256, 256, 3)\n",
            "(895, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npyGmpDf2yD6"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbqxC8fyuoy2"
      },
      "source": [
        "class CUB200(data.Dataset):\n",
        "\n",
        "    def __init__(self, type, transform = None):\n",
        "        super(CUB200, self).__init__()\n",
        "        \"\"\"\n",
        "        type : int = 1, 2, 3\n",
        "        \"\"\"\n",
        "        \n",
        "        if type == CUB200_TYPE_TRAIN:\n",
        "          self.image = train_data\n",
        "          self.label = train_label\n",
        "        elif type == CUB200_TYPE_TEST:\n",
        "          self.image = test_data\n",
        "          self.label = test_label\n",
        "        elif type == CUB200_TYPE_SUBMIT:\n",
        "          self.image = np.load(default_path + 'test_image.npy')\n",
        "          self.label = np.zeros(500)\n",
        "        \n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.image[index], self.label[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QH5Xj02Vgu5",
        "outputId": "445b34d8-d837-4b60-a777-9fa456ba86cb"
      },
      "source": [
        "trainCUB = CUB200(CUB200_TYPE_TRAIN)\n",
        "print(trainCUB.image.shape)\n",
        "print(trainCUB.label.shape)\n",
        "\n",
        "testCUB = CUB200(CUB200_TYPE_TEST)\n",
        "print(testCUB.image.shape)\n",
        "print(testCUB.label.shape)\n",
        "# print(np.max(testCUB.label), np.min(testCUB.label))\n",
        "\n",
        "submitCUB = CUB200(CUB200_TYPE_SUBMIT)\n",
        "print(submitCUB.image.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3467, 256, 256, 3)\n",
            "(3467,)\n",
            "(386, 256, 256, 3)\n",
            "(386,)\n",
            "(500, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "245P8QOlMjkD",
        "outputId": "b2314637-1ca3-41c1-fbcf-cbef2d380c0d"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TkTeovfMkvI"
      },
      "source": [
        "# train_data에만 data augmentaion을 적용\n",
        "transform_train = transforms.Compose([\n",
        "        # transforms.Resize(512),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        # transforms.Resize(512),\n",
        "        # transforms.CenterCrop(448),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytid3c0vMlsI"
      },
      "source": [
        "# CUSTOM DATASET을 이용하여 train_loader, test_loader을 구축\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = CUB200(CUB200_TYPE_TRAIN, transform = transform_train),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = CUB200(CUB200_TYPE_TEST, transform = transform_test),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "submit_loader = torch.utils.data.DataLoader(\n",
        "    dataset = CUB200(CUB200_TYPE_SUBMIT, transform = transform_test),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vlnqo9sM1DH"
      },
      "source": [
        "def training_model(model, criterion, optimizer, scheduler, num_epochs = 25):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if i % 60 == 59:\n",
        "                print('[%d, %5d] loss: %.7f' %\n",
        "                    (epoch + 1, (i + 1), running_loss / 20))\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        # gunmo\n",
        "        # scheduler.step()\n",
        "\n",
        "\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.squeeze()\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print('[%d epoch] Accuracy of the network on the train images: %d %%' %\n",
        "              (epoch + 1, 100 * train_correct / train_total))\n",
        "        \n",
        "    print(\"End Training do it eval_accuracy\")\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmDHs5-65Ycs"
      },
      "source": [
        "def eval_accuracy(model):\n",
        "    class_correct = list(0. for i in range(50))\n",
        "    class_total = list(0. for i in range(50))\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "                    \n",
        "            for i in range(labels.shape[0]):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "                \n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on test images: %d %%' % (\n",
        "        100 * correct / total))            \n",
        "                \n",
        "    return 100 * correct / total"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoAfC_44xBek"
      },
      "source": [
        "class Interpolate(nn.Module):\n",
        "    def __init__(self, size, mode):\n",
        "        super(Interpolate, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=True)\n",
        "        return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51GN41VPZ5vg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "124607c81649405286b9aeb51492afb6",
            "37bb0a0fa6054a438f0f0a16fceb464e",
            "f170bf32404441748b4a4dd03c5f825d",
            "fa55a0847e9a43d784baaec279c41eac",
            "ed42bd36332541a3994d74fe15161b2b",
            "25d7945a5cfe47c3a851a5f2b7b546ed",
            "8a72ba5e854942398f9112d42f4ed2a6",
            "f189b259501c4aee8f65bfe2de27aa0f"
          ]
        },
        "outputId": "9bfaf25d-b63e-42d1-c1e1-a493a8612d89"
      },
      "source": [
        "\n",
        "\n",
        "model_ft = models.resnet152(pretrained=True)\n",
        "for param in model_ft.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# model_ft.conv1 = nn.Sequential(\n",
        "#     # Interpolate(size=(512, 512), mode='bilinear'),\n",
        "#     nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "# )\n",
        "\n",
        "model_ft.fc = nn.Sequential(\n",
        "        nn.Linear(model_ft.fc.in_features, 50),\n",
        "        # nn.Linear(2048, 50),\n",
        "        # nn.Linear(512, 256),\n",
        "        # nn.Linear(256, 50),\n",
        "        # nn.Softmax(),\n",
        "    )\n",
        "# model_ft"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "124607c81649405286b9aeb51492afb6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSLXg--VzhAi"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIUPBgFCxzUG"
      },
      "source": [
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#     process = psutil.Process(os.getpid())\n",
        "#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()\n",
        "\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjcQV0A6M3bx",
        "outputId": "ccccf6ca-fa7d-4fc8-e2b5-34fd03f327e2"
      },
      "source": [
        "num_epochs = 16\n",
        "model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ft.parameters(), lr = 0.0008)\n",
        "# optimizer = optim.SGD(model_ft.parameters(), lr=0.0075, momentum=0.9)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 16, gamma = 0.1)\n",
        "# lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20,40], gamma= 0.1)  \n",
        "\n",
        "model_ft = training_model(model_ft, criterion, optimizer, lr_scheduler, num_epochs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    60] loss: 9.1423422\n",
            "[1 epoch] Accuracy of the network on the train images: 75 %\n",
            "[2,    60] loss: 3.6406914\n",
            "[2 epoch] Accuracy of the network on the train images: 82 %\n",
            "[3,    60] loss: 2.4515760\n",
            "[3 epoch] Accuracy of the network on the train images: 86 %\n",
            "[4,    60] loss: 1.8878198\n",
            "[4 epoch] Accuracy of the network on the train images: 87 %\n",
            "[5,    60] loss: 1.6446251\n",
            "[5 epoch] Accuracy of the network on the train images: 87 %\n",
            "[6,    60] loss: 1.4065498\n",
            "[6 epoch] Accuracy of the network on the train images: 90 %\n",
            "[7,    60] loss: 1.3054651\n",
            "[7 epoch] Accuracy of the network on the train images: 90 %\n",
            "[8,    60] loss: 1.0814185\n",
            "[8 epoch] Accuracy of the network on the train images: 89 %\n",
            "[9,    60] loss: 1.1059019\n",
            "[9 epoch] Accuracy of the network on the train images: 90 %\n",
            "[10,    60] loss: 0.9657002\n",
            "[10 epoch] Accuracy of the network on the train images: 93 %\n",
            "[11,    60] loss: 0.9279315\n",
            "[11 epoch] Accuracy of the network on the train images: 92 %\n",
            "[12,    60] loss: 0.7896270\n",
            "[12 epoch] Accuracy of the network on the train images: 93 %\n",
            "[13,    60] loss: 0.7865468\n",
            "[13 epoch] Accuracy of the network on the train images: 93 %\n",
            "[14,    60] loss: 0.7846983\n",
            "[14 epoch] Accuracy of the network on the train images: 93 %\n",
            "[15,    60] loss: 0.7698492\n",
            "[15 epoch] Accuracy of the network on the train images: 94 %\n",
            "[16,    60] loss: 0.6091621\n",
            "[16 epoch] Accuracy of the network on the train images: 95 %\n",
            "End Training do it eval_accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCtc86RPepo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8658a8d4-ed65-48a4-fb3d-d435e3db638e"
      },
      "source": [
        "eval_acc = eval_accuracy(model_ft)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on test images: 81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aJbryDvNmhQ"
      },
      "source": [
        "import itertools\n",
        "\n",
        "def get_result(model):\n",
        "  result = []\n",
        "  confidence = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(submit_loader, 0):\n",
        "      images, _ = data\n",
        "      images = images.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      result.append(predicted.cpu().numpy())\n",
        "\n",
        "      for output in outputs:\n",
        "        confidence.append(torch.max(F.softmax(output, dim=0)).cpu().numpy())\n",
        "  \n",
        "  result = list(itertools.chain(*result))\n",
        "\n",
        "  ca = np.array(confidence)\n",
        "  # print(ca)\n",
        "  confidence_count = len(np.where(ca > 0.9)[0])\n",
        "  print(confidence_count)\n",
        "  \n",
        "  additional_train_data = []\n",
        "  additional_train_label = []\n",
        "\n",
        "  submit_image = submit_loader.dataset.image\n",
        "\n",
        "  # print(result)\n",
        "\n",
        "  for i in np.where(ca > 0.9)[0]:\n",
        "    additional_train_data.append(submit_image[i])\n",
        "    additional_train_label.append(result[i])\n",
        "  \n",
        "  # Remeber prev data\n",
        "  import shutil\n",
        "  shutil.copy(default_path + f\"additional_image.npy\", default_path + f\"additional_library/additional_image_{confidence_count}_{eval_acc}%.npy\")\n",
        "  shutil.copy(default_path + f\"additional_label.npy\", default_path + f\"additional_library/additional_label_{confidence_count}_{eval_acc}%.npy\")\n",
        "  \n",
        "  #store new data\n",
        "  np.save(default_path + \"additional_image.npy\", additional_train_data)\n",
        "  np.save(default_path + \"additional_label.npy\", additional_train_label)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-rzBUi6FK9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b6db15-77a1-4a6a-c16e-781a581192ab"
      },
      "source": [
        "submit_result = get_result(model_ft)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUiVgOC2J2R4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948d3c16-ed91-4c4b-c69f-3a8b050f4ea4"
      },
      "source": [
        "print(submit_result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[16, 12, 23, 23, 47, 26, 38, 24, 16, 30, 28, 47, 41, 20, 35, 26, 15, 8, 37, 7, 4, 22, 22, 32, 38, 2, 40, 36, 30, 34, 42, 37, 45, 35, 10, 33, 5, 7, 40, 48, 32, 37, 32, 7, 8, 43, 22, 24, 39, 16, 12, 25, 5, 6, 32, 48, 42, 39, 8, 45, 0, 5, 45, 12, 14, 26, 40, 49, 3, 9, 48, 11, 9, 35, 12, 20, 40, 36, 42, 35, 45, 41, 36, 26, 22, 6, 4, 48, 8, 48, 33, 44, 19, 14, 34, 9, 14, 21, 4, 27, 19, 35, 21, 23, 45, 4, 9, 44, 18, 24, 10, 47, 1, 48, 25, 11, 42, 31, 42, 35, 3, 0, 21, 29, 14, 10, 38, 18, 26, 1, 32, 35, 44, 1, 9, 33, 43, 37, 16, 2, 40, 38, 3, 38, 15, 34, 26, 12, 34, 41, 11, 6, 39, 43, 38, 0, 22, 42, 3, 38, 1, 13, 41, 15, 21, 41, 14, 10, 13, 28, 49, 44, 41, 19, 7, 27, 46, 26, 11, 13, 46, 20, 35, 42, 24, 25, 15, 42, 6, 42, 36, 27, 6, 12, 48, 25, 29, 5, 6, 26, 2, 13, 15, 29, 2, 17, 9, 14, 6, 4, 44, 38, 21, 26, 24, 21, 29, 46, 2, 27, 48, 22, 31, 12, 31, 2, 17, 18, 13, 24, 35, 8, 27, 37, 4, 18, 29, 20, 20, 8, 49, 24, 40, 13, 19, 38, 49, 6, 6, 4, 31, 34, 20, 48, 1, 42, 10, 35, 26, 10, 29, 9, 27, 47, 0, 32, 40, 41, 27, 11, 2, 31, 33, 23, 45, 45, 17, 0, 17, 8, 0, 22, 13, 6, 48, 35, 9, 49, 30, 8, 13, 17, 1, 0, 8, 25, 42, 10, 43, 30, 23, 21, 17, 38, 3, 27, 36, 20, 2, 46, 45, 12, 46, 1, 36, 20, 21, 42, 19, 17, 17, 43, 40, 37, 45, 28, 5, 19, 5, 36, 31, 12, 16, 38, 4, 9, 17, 14, 2, 29, 15, 23, 41, 26, 16, 27, 1, 5, 10, 32, 10, 42, 45, 16, 16, 15, 24, 5, 25, 38, 36, 27, 40, 19, 29, 11, 2, 32, 7, 10, 3, 20, 33, 18, 47, 16, 31, 19, 47, 47, 1, 13, 21, 14, 36, 25, 3, 10, 7, 39, 45, 37, 20, 17, 8, 34, 25, 10, 37, 0, 41, 46, 34, 39, 28, 27, 19, 45, 34, 0, 37, 28, 34, 9, 9, 4, 28, 8, 0, 2, 48, 5, 23, 28, 33, 46, 45, 13, 43, 16, 49, 23, 17, 11, 37, 47, 29, 27, 26, 34, 35, 3, 24, 14, 49, 28, 40, 34, 29, 11, 0, 13, 7, 18, 23, 15, 25, 47, 39, 9, 28, 40, 44, 29, 4, 1, 4, 42, 18, 5, 13, 19, 12, 17, 40, 10, 21, 23, 15, 46, 14, 16, 9, 39, 7, 24, 47, 41, 7, 27, 25, 17, 24, 28, 20, 7, 39, 46, 13, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6ONJVhtKIIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de64265-8d27-4feb-dc49-73cf1dd3369c"
      },
      "source": [
        "pip install pycryptodomex --no-binary :all:"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycryptodomex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/e2/a0f9f5452a59bafaa3420585f22b58a8566c4717a88c139af2276bb5695d/pycryptodomex-3.10.1.tar.gz (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 13.7MB/s \n",
            "\u001b[?25hSkipping wheel build for pycryptodomex, due to binaries being disabled for it.\n",
            "Installing collected packages: pycryptodomex\n",
            "    Running setup.py install for pycryptodomex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed pycryptodomex-3.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oMQLPBuI7Jo"
      },
      "source": [
        "import json\n",
        "from base64 import b64encode\n",
        "from Cryptodome.Cipher import AES\n",
        "from Cryptodome.Util.Padding import pad\n",
        "\n",
        "def read_txt(fileName):\n",
        "    with open(fileName, 'rt') as f:\n",
        "        list_data = [a.strip('\\n\\r') for a in f.readlines()]\n",
        "    return list_data\n",
        "\n",
        "def write_json(fileName, data):\n",
        "    with open(fileName, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def load_key(key_path):\n",
        "    with open(key_path, \"rb\") as f:\n",
        "        key = f.read()\n",
        "    return key\n",
        "\n",
        "def encrypt_data(key_path, ans_list, encrypt_store_path='ans.json'):\n",
        "    key = load_key(key_path)\n",
        "    print(key)\n",
        "    data = \" \".join([str(i) for i in ans_list])\n",
        "    encode_data = data.encode()\n",
        "    cipher = AES.new(key, AES.MODE_CBC)\n",
        "    ct_bytes = cipher.encrypt(pad(encode_data, AES.block_size))\n",
        "    iv = b64encode(cipher.iv).decode('utf-8')\n",
        "    ct = b64encode(ct_bytes).decode('utf-8')\n",
        "    write_json(encrypt_store_path, {'iv':iv, 'ciphertext':ct})\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # 1.이메일을 통해서 전달 받은 키 파일의 경로 입력\n",
        "    key_path = default_path + \"team9.pem\"\n",
        "    # key_path = \"/content/drive/My Drive/ColabNotebooks/aiproject/team9.pem\"\n",
        "    # 2. 예측한 결과를 텍스트 파일로 저장했을 경우 리스트로 다시 불러오기\n",
        "    # 본인이 원하는 방식으로 리스트 형태로 예측 값을 불러오기만 하면 됨(순서를 지킬것)\n",
        "    #raw_ans_path = \"ans.txt\"\n",
        "    #ans = read_txt(raw_ans_path)\n",
        "    #ans에 result 저장한 리스트 넣기\n",
        "    ans = submit_result\n",
        "    # 3. 암호화된 파일을 저장할 위치\n",
        "    encrypt_ans_path = default_path + \"ai_answer.json\"\n",
        "    # 4. 암호화!(pycrytodome 설치)\n",
        "    encrypt_data(key_path, ans, encrypt_ans_path)\n",
        "    print(\"finished!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E3dovK9Lbv8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21AhnqMiJdQ0"
      },
      "source": [
        "0 0 0 0 ... 50\n",
        "...\n",
        "500\n",
        "\n",
        "np.torch([0 0 0 0 0])\n",
        "\n"
      ]
    }
  ]
}