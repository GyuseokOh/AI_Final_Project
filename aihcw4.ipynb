{"cells":[{"cell_type":"markdown","metadata":{"id":"F1bPPSg1NZJm"},"source":["# 재구축 데이터셋 Scratch\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2321,"status":"ok","timestamp":1623395126224,"user":{"displayName":"오규석","photoUrl":"","userId":"11076778257915679187"},"user_tz":-540},"id":"dHIByFLlYcpy"},"outputs":[],"source":["import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets, models\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import TensorDataset\n","from PIL import Image\n","import numpy as np\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nfU_Y_gSMc42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# 구축된 .npy파일을 Pytorch DataLoader을 사용할 수 있도록 CUSTOM DATASET을 만듬.\n","import numpy as np\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","\n","default_path = \"/content/drive/MyDrive/인공지능 수업/final/\"\n","\n","CUB200_TYPE_TRAIN = 1\n","CUB200_TYPE_TEST = 2\n","CUB200_TYPE_SUBMIT = 3\n","\n","drive.mount('/content/drive')\n","class CUB200(data.Dataset):\n","\n","    def __init__(self, type, transform = None):\n","        super(CUB200, self).__init__()\n","        \"\"\"\n","        type : int = 1, 2, 3\n","        \"\"\"\n","\n","        # train_data = np.load(default_path + 'train_image.npy')\n","        # train_label = np.load(default_path + 'train_label.npy')\n","\n","        original_train_data = np.load(default_path + 'train_image.npy')\n","        original_train_label = np.load(default_path + 'train_label.npy')\n","\n","        train_data, test_data, train_label, test_label = train_test_split(\n","            original_train_data,\n","            original_train_label,\n","            test_size = 0.3,\n","            random_state = 1)\n","        \n","        if type == CUB200_TYPE_TRAIN:\n","          self.image = train_data\n","          self.label = train_label\n","        elif type == CUB200_TYPE_TEST:\n","          self.image = test_data\n","          self.label = test_label\n","        elif type == CUB200_TYPE_SUBMIT:\n","          self.image = np.load(default_path + 'test_image.npy')\n","          self.label = np.zeros(500)\n","        \n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img, target = self.image[index], self.label[index]\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QH5Xj02Vgu5"},"outputs":[],"source":["trainCUB = CUB200(CUB200_TYPE_TRAIN)\n","print(trainCUB.image.shape)\n","print(trainCUB.label.shape)\n","\n","testCUB = CUB200(CUB200_TYPE_TEST)\n","print(testCUB.image.shape)\n","print(testCUB.label.shape)\n","print(np.max(testCUB.label), np.min(testCUB.label))\n","\n","submitCUB = CUB200(CUB200_TYPE_SUBMIT)\n","print(submitCUB.image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"245P8QOlMjkD"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TkTeovfMkvI"},"outputs":[],"source":["# train_data에만 data augmentaion을 적용\n","transform_train = transforms.Compose([\n","        transfroms.Rs\n","        transforms.RandomCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n","\n","transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JR5NgHTItVvg"},"outputs":[],"source":["linear1 = nn.Linear(2048, 1024, bias=True)\n","linear1_1 = nn.Linear(2048, 50, bias=True)\n","linear1_2 = nn.Linear(2048, 50, bias=True)\n","linear1_3 = nn.Linear(2048, 50, bias=True)\n","linear2 = nn.Linear(1024, 50, bias=True)\n","linear3 = nn.Linear(512, 50, bias=True)\n","relu = nn.ReLU()\n","\n","# xavier initialization\n","nn.init.xavier_uniform_(linear1.weight)\n","nn.init.xavier_uniform_(linear2.weight)\n","nn.init.xavier_uniform_(linear3.weight)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytid3c0vMlsI"},"outputs":[],"source":["# CUSTOM DATASET을 이용하여 train_loader, test_loader을 구축\n","\n","batch_size = 4\n","\n","train_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(CUB200_TYPE_TRAIN, transform = transform_train),\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(CUB200_TYPE_TEST, transform = transform_test),\n","    batch_size = batch_size,\n","    shuffle = False\n",")\n","\n","submit_loader = torch.utils.data.DataLoader(\n","    dataset = CUB200(CUB200_TYPE_SUBMIT, transform = transform_test),\n","    batch_size = batch_size,\n","    shuffle = False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Vlnqo9sM1DH"},"outputs":[],"source":["def training_model(model, criterion, optimizer, scheduler, num_epochs = 25):\n","\n","    for epoch in range(num_epochs):\n","        scheduler.step()\n","\n","        running_loss = 0.0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            if i % 60 == 59:\n","                print('[%d, %5d] loss: %.7f' %\n","                    (epoch + 1, (i + 1), running_loss / 20))\n","                running_loss = 0.0\n","        \n","        train_correct = 0\n","        train_total = 0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs = inputs.squeeze()\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_total += labels.size(0)\n","            train_correct += (predicted == labels).sum().item()\n","\n","        print('[%d epoch] Accuracy of the network on the train images: %d %%' %\n","              (epoch + 1, 100 * train_correct / train_total))\n","        \n","    print(\"End Training do it eval_accuracy\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmDHs5-65Ycs"},"outputs":[],"source":["def eval_accuracy(model):\n","    class_correct = list(0. for i in range(50))\n","    class_total = list(0. for i in range(50))\n","\n","    correct = 0\n","    total = 0\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        for i, data in enumerate(test_loader, 0):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            c = (predicted == labels).squeeze()\n","                    \n","            for i in range(labels.shape[0]):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","                \n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on test images: %d %%' % (\n","        100 * correct / total))            \n","                \n","    return "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51GN41VPZ5vg"},"outputs":[],"source":["model_ft = models.resnext101_32x8d(pretrained=True)\n","for param in model_ft.parameters():\n","  param.requires_grad = False\n","print(model_ft)\n","model_ft.fc = nn.Sequential(\n","                      linear1\n",")\n","print(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjcQV0A6M3bx"},"outputs":[],"source":["#0.001: 72퍼\n","#0.05 = 72퍼\n","#0.0075 25에폭 : 74퍼\n","#0.0008 이미지 사이즈 400 70퍼\n","num_epochs = 25\n","model_ft.to(device)\n","criterion = nn.CrossEntropyLoss()\n","#optimizer = optim.Adam(model_ft.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.3, amsgrad=False)\n","optimizer = optim.SGD(model_ft.parameters(), lr=0.1, momentum=0.9)\n","lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 16, gamma = 0.1)\n","\n","model_ft = training_model(model_ft, criterion, optimizer, lr_scheduler, num_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xaCtc86RPepo"},"outputs":[],"source":["eval_accuracy(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aJbryDvNmhQ"},"outputs":[],"source":["import itertools\n","\n","def get_result(model):\n","  result=[]\n","  model.eval()\n","  with torch.no_grad():\n","    for i, data in enumerate(submit_loader, 0):\n","      images, _ = data\n","      images = images.to(device)\n","      outputs = model(images)\n","      _, predicted = torch.max(outputs, 1)\n","      result.append(predicted.cpu().numpy())\n","  return list(itertools.chain(*result))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-rzBUi6FK9s"},"outputs":[],"source":["submit_result = get_result(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6ONJVhtKIIh"},"outputs":[],"source":["pip install pycryptodomex --no-binary :all:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8oMQLPBuI7Jo"},"outputs":[],"source":["import json\n","from base64 import b64encode\n","from Cryptodome.Cipher import AES\n","from Cryptodome.Util.Padding import pad\n","\n","def read_txt(fileName):\n","    with open(fileName, 'rt') as f:\n","        list_data = [a.strip('\\n\\r') for a in f.readlines()]\n","    return list_data\n","\n","def write_json(fileName, data):\n","    with open(fileName, 'w', encoding='utf-8') as f:\n","        json.dump(data, f, ensure_ascii=False, indent=4)\n","\n","def load_key(key_path):\n","    with open(key_path, \"rb\") as f:\n","        key = f.read()\n","    return key\n","\n","def encrypt_data(key_path, ans_list, encrypt_store_path='ans.json'):\n","    key = load_key(key_path)\n","    print(key)\n","    data = \" \".join([str(i) for i in ans_list])\n","    encode_data = data.encode()\n","    cipher = AES.new(key, AES.MODE_CBC)\n","    ct_bytes = cipher.encrypt(pad(encode_data, AES.block_size))\n","    iv = b64encode(cipher.iv).decode('utf-8')\n","    ct = b64encode(ct_bytes).decode('utf-8')\n","    write_json(encrypt_store_path, {'iv':iv, 'ciphertext':ct})\n","\n","if __name__==\"__main__\":\n","    # 1.이메일을 통해서 전달 받은 키 파일의 경로 입력\n","    #key_path = default_path + \"team9.pem\"\n","    key_path = \"/content/drive/MyDrive/인공지능 수업/team9.pem\"\n","    # 2. 예측한 결과를 텍스트 파일로 저장했을 경우 리스트로 다시 불러오기\n","    # 본인이 원하는 방식으로 리스트 형태로 예측 값을 불러오기만 하면 됨(순서를 지킬것)\n","    #raw_ans_path = \"ans.txt\"\n","    #ans = read_txt(raw_ans_path)\n","    #ans에 result 저장한 리스트 넣기\n","    ans = submit_result\n","    # 3. 암호화된 파일을 저장할 위치\n","    encrypt_ans_path = default_path + \"ai_4_answer.json\"\n","    # 4. 암호화!(pycrytodome 설치)\n","    encrypt_data(key_path, ans, encrypt_ans_path)\n","    print(\"finished!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2E3dovK9Lbv8"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"21AhnqMiJdQ0"},"source":["0 0 0 0 ... 50\n","...\n","500\n","\n","np.torch([0 0 0 0 0])\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"aihcw4.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}